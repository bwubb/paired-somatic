import tabix
import csv
import os
import errno
from pybedtools import BedTool

def mkdir_p(path):
    try:
        os.makedirs(path)
    except OSError as exc: # Python >2.5
        if exc.errno==errno.EEXIST and os.path.isdir(path):
            pass

#sample_list in config, default is samples.list
with open(config.get('project',{}).get('sample_list','samples.list'),'r') as i:
    SAMPLES=i.read().splitlines()

with open(config.get('project',{}).get('pair_list','pairs.list'),'r') as p:
    PAIRS=dict(line.split('\t') for line in p.read().splitlines())

#checking for bams:
missing_bam=0
for sample in SAMPLES:
    mkdir_p('logs/cluster/%s' % sample)

if config['project'].get('bam_list',False):
    with open(config['project']['bam_list'],'r') as b:
        BAMS=dict(line.split('\t') for line in b.read().splitlines())
else:
    BAMS=False
    if not os.path.isfile('bam_input/final/{sample}/{reference}/{sample}.ready.bam'.format(sample=sample,reference=config['resources']['reference']['key'])):
        print('WARNING: < %s > Missing BAM!' % sample)
        missing_bam+=1
    if missing_bam>0:
        raise

def paired_bams(wildcards):
    ref=config['resources']['reference']['key']
    tumor=wildcards.tumor
    normal=PAIRS[wildcards.tumor]
    if config['project'].get('bam_list',False):
        return {'tumor':BAMS[wildcards.tumor],'normal':BAMS[normal]}
    else:
        return {'tumor':'bam_input/final/{tumor}/{ref}/{tumor}.ready.bam'.format(tumor=tumor,ref=ref),'normal':'bam_input/final/{normal}/{ref}/{normal}.ready.bam'.format(normal=normal,ref=ref)}

def paired_pileup(wildcards):
    targets=config['resources']['library']['targets_key']
    tumor=wildcards.tumor
    normal=PAIRS[wildcards.tumor]
    return {'tumor':'data/work/{tumor}/{targets}/sequenza/raw.mpileup'.format(tumor=tumor,targets=targets),'normal':'data/work/{normal}/{targets}/sequenza/raw.mpileup'.format(normal=normal,targets=targets)}

def sample_bam(wildcards):
    if getattr(wildcards,'tumor',False):
        name=wildcards.tumor
    elif getattr(wildcards,'normal',False):
        name=wildcards.normal
    else:
        name=wildcards.sample
    if config['project'].get('bam_list',False):
        return BAMS[name]
    return 'bam_input/final/{sample}/{reference}/{sample}.ready.bam'.format(sample=name,reference=config['resources']['reference']['key'])

def get_purity(wildcards):
    with open(f'data/work/{wildcards.tumor}/{wildcards.targets}/sequenza/{wildcards.tumor}_confints_CP.txt','r') as file:
        lines=file.read().splitlines()
        return lines[3].split('\t')[0]#3 for max
    #else:
    #    return '1.0'

def readcount_bam(wildcards):#The use of BAMS is all messed up
    #print(BAMS[wildcards.tumor])
    ref=config['resources']['reference']['key']
    if getattr(wildcards,'class','')=='Somatic':
        name=wildcards.tumor
        #return f'bam_input/final/{wildcards.tumor}/{ref}/{wildcards.tumor}.ready.bam'
    else:
        #return f'bam_input/final/{PAIRS[wildcards.tumor]}/{ref}/{PAIRS[wildcards.tumor]}.ready.bam'
        name=PAIRS[wildcards.tumor]
    if config['project'].get('bam_list',False):
        return BAMS[name]
    else:
        return f'bam_input/final/{name}/{ref}/{name}.ready.bam'

rule all:
    input:
        expand("data/work/{tumor}/{targets}/varscan/somatic.fpfilter.vcf.gz",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key']),
        expand("data/work/{tumor}/{targets}/mutect/somatic.twice_filtered.vcf.gz",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key']),
        expand("data/work/{tumor}/{targets}/vardict/somatic.twice_filtered.vcf.gz",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key']),
        expand("data/work/{tumor}/{targets}/strelka/somatic.raw.vcf.gz",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key'])

rule concordant_file:
    input:
        expand("data/work/{tumor}/{targets}/concordant/sites.txt",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key'])

rule only_Mutect:
    input:
        expand("data/work/{tumor}/{targets}/mutect/somatic.raw.vcf.gz",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key'])

rule only_VarScan:
    input:
        expand("data/work/{tumor}/{targets}/varscan/somatic.fpfilter.vcf.gz",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key']),
        expand("data/work/{tumor}/{targets}/varscan/loh.fpfilter.vcf.gz",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key']),
        expand("data/work/{tumor}/{targets}/varscan/germline.fpfilter.vcf.gz",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key'])

rule only_VarDict:
    input:
        expand("data/work/{tumor}/{targets}/vardict/somatic.twice_filtered.vcf.gz",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key']),
        expand("data/work/{tumor}/{targets}/vardict/loh.twice_filtered.vcf.gz",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key']),
        expand("data/work/{tumor}/{targets}/vardict/germline.twice_filtered.vcf.gz",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key'])

rule intersect_other_things:
    input:
        expand("data/work/{tumor}/{targets}/concordant/loh_sites.txt",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key']),
        expand("data/work/{tumor}/{targets}/concordant/germline_sites.txt",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key']),

rule only_Strelka2:
    input:
        expand("data/work/{tumor}/{targets}/strelka/results/variants/somatic.raw.vcf.gz",tumor=PAIRS.keys(),targets=config['resources']['library']['targets_key'])

#So rather then doing --bamOut options intitially, several of the tools including Mutect may have capability to provide intervals of manually filtered active regions.
#Here is the list of things I want to look at.

#Common bi-allelic mutations, maybe from ExAC? or gnomAD

rule MuTect2:
    input:
        unpack(paired_bams)
    output:#--bamOutput {output.bam}
        raw="data/work/{tumor}/{targets}/mutect/somatic.raw.vcf.gz",
        snps="data/work/{tumor}/{targets}/mutect/somatic.snps.vcf.gz",
        indels="data/work/{tumor}/{targets}/mutect/somatic.indels.vcf.gz"
    params:
        ref=config['resources']['reference']['fasta'],
        #cosmic='/home/bwubb/resources/Vcf_files/CosmicCodingMuts_v69_b37.vcf',
        intervals=config['resources']['library']['targets_intervals'],
        memory='16g',
        tumor=lambda wildcards: wildcards.tumor,
        normal=lambda wildcards: PAIRS[wildcards.tumor]
    shell:
        """
        gatk --java-options '-Xmx{params.memory}' Mutect2 -R {params.ref} -I {input.tumor} -I {input.normal} -tumor {params.tumor} -normal {params.normal} -L {params.intervals} -O {output.raw}
        gatk --java-options '-Xmx{params.memory}' SelectVariants -R {params.ref} -V {output.raw} -O {output.snps} -select-type SNP
        gatk --java-options '-Xmx{params.memory}' SelectVariants -R {params.ref} -V {output.raw} -O {output.indels} -select-type INDEL
        """
#If GRCh38 consider adding --disable-read-filter MateOnSameContigOrNoMappedMateReadFilter, see documentation for details
rule CalculateContamination:
    input:
        unpack(paired_bams)
    output:
        pileup="data/work/{tumor}/{targets}/mutect/getpileupsummaries.table",
        contamination="data/work/{tumor}/{targets}/mutect/calculatecontamination.table"
        #metrics?
    params:
        #allele=config['resources']['library']['gnomad.vcf']#could infer if I forget to place it, or I could have it made if it doesnt exist
        allele="$HOME/resources/Vcf_files/gnomad.exomes.r2.0.2.sites.S07604715.common_biallelic_snps.simplified.vcf.gz"
    shell:
        """
        gatk GetPileupSummaries -I {input.tumor} -V {params.allele} -O {output.pileup}
        gatk CalculateContamination -I {output.pileup} -O {output.contamination}
        """

rule FilterMutectCall:
    input:
        vcf="data/work/{tumor}/{targets}/mutect/somatic.raw.vcf.gz",
        contamination="data/work/{tumor}/{targets}/mutect/calculatecontamination.table"#Can I run filter without contamination? How can I find germline mutations for loh validation?
    output:
        "data/work/{tumor}/{targets}/mutect/somatic.once_filtered.vcf.gz"
    shell:
        "gatk FilterMutectCalls -V {input.vcf} --contamination-table {input.contamination} -O {output}"

rule CollectSequencingArtifactMetrics:
    input:
        unpack(paired_bams)
    output:
        "data/work/{tumor}/{targets}/mutect/tumor_artifact.pre_adapter_detail_metrics.txt"
    params:
        ref=config['resources']['reference']['fasta'],
        output_p="data/work/{tumor}/{targets}/mutect/tumor_artifact"
    shell:
        'gatk CollectSequencingArtifactMetrics -R {params.ref} -I {input.tumor} -O {params.output_p} --FILE_EXTENSION ".txt"'

rule FilterOrientationBias:
    input:
        vcf="data/work/{tumor}/{targets}/mutect/somatic.once_filtered.vcf.gz",
        metrics="data/work/{tumor}/{targets}/mutect/tumor_artifact.pre_adapter_detail_metrics.txt"
    output:
        "data/work/{tumor}/{targets}/mutect/somatic.twice_filtered.vcf.gz"
    shell:
        "gatk FilterByOrientationBias -AM G/T -AM C/T -V {input.vcf} -P {input.metrics} -O {output}"

rule VarDictJava:#First a more lenient -P val, not sure what
    input:
        unpack(paired_bams)
    output:
        raw="data/work/{tumor}/{targets}/vardict/vardict.raw.vcf.gz"
    params:
        prefix=lambda wildcards: 'data/work/{tumor}/{targets}/vardict/somatic'.format(tumor=wildcards.tumor,targets=wildcards.targets),
        ref=config['resources']['reference']['fasta'],
        bed=config['resources']['library']['targets_bed'],
        path="$HOME/software/VarDictJava/VarDict",
        normal=lambda wildcards: PAIRS[wildcards.tumor],
        AF_THR=0.01
    threads:
        4
    shell:#split to snps and indels
        """
        $HOME/software/VarDictJava/build/install/VarDict/bin/VarDict -th {threads} -G {params.ref} -f {params.AF_THR} -N {wildcards.tumor} -b '{input.tumor}|{input.normal}' -c 1 -S 2 -E 3 -g 4 {params.bed} | {params.path}/testsomatic.R | {params.path}/var2vcf_paired.pl -N '{wildcards.tumor}|{params.normal}' -f {params.AF_THR} | bgzip -c > {output.raw}
        tabix -p vcf {output.raw}
        """

rule VarDictFilter:
    input:
        "data/work/{tumor}/{targets}/vardict/vardict.raw.vcf.gz"
    output:
        once="data/work/{tumor}/{targets}/vardict/vardict.once_filtered.vcf.gz",
        twice="data/work/{tumor}/{targets}/vardict/vardict.twice_filtered.vcf.gz"
    shell:
        """
        bcftools filter --threads {threads} -e '((FORMAT/AF * FORMAT/DP < 6) && ((FORMAT/MQ < 55.0 && FORMAT/NM > 1.0) || (FORMAT/MQ < 60.0 && FORMAT/NM > 2.0) || (FORMAT/DP < 10) || (FORMAT/QUAL < 45)))' -s filter_1 -m + -O z {input} > {output.once}
        tabix -p vcf {output.once}
        bcftools filter --threads {threads} -e 'FORMAT/AF < 0.2 && FORMAT/QUAL < 55 && INFO/SSF > 0.06' -s filter_2 -m + -O z {output.once} > {output.twice}
        tabix -p vcf {output.twice}
        """
        #bcftools view -f PASS -i 'INFO/STATUS=="StrongSomatic" || INFO/STATUS=="LikelySomatic"' > somatic

rule process_VarDict: #split vardict into loh, germline, somatic
    input:
        "data/work/{tumor}/{targets}/vardict/vardict.twice_filtered.vcf.gz"
    output:
        somatic="data/work/{tumor}/{targets}/vardict/somatic.twice_filtered.vcf.gz",
        loh="data/work/{tumor}/{targets}/vardict/loh.twice_filtered.vcf.gz",
        germline="data/work/{tumor}/{targets}/vardict/germline.twice_filtered.vcf.gz"
    shell:
        """
        bcftools view -f PASS -i 'INFO/STATUS==\"StrongSomatic\" || INFO/STATUS==\"LikelySomatic\"' -O z -o {output.somatic} {input} && tabix -p vcf {output.somatic}
        bcftools view -f PASS -i 'INFO/STATUS==\"StrongLOH\" || INFO/STATUS==\"LikelyLOH\"' -O z -o {output.loh} {input} && tabix -p vcf {output.loh}
        bcftools view -f PASS -i 'INFO/STATUS==\"Germline\"' -O z -o {output.germline} {input} && tabix -p vcf {output.germline}
        """

rule raw_mpileup:
    input:
        sample_bam
    output:
        "data/work/{sample}/{targets}/sequenza/raw.mpileup"
    params:
        ref=config['resources']['reference']['fasta']
    shell:
        "samtools mpileup -A -o {output} -f {params.ref} -Q 20 {input}"
        #What does -B do, remove BAQ but will it work for sequenza still?
        #-B recommended for VarScan
        #-R --ignore-RG         ignore RG tags (one BAM = one sample)
        #

#This is too much for exome. It needs to be done chr at a time and concatenated
rule sort_mpileup:
    input:
        "data/work/{sample}/{reference}/sequenza/raw.mpileup"
    output:
        "data/work/{sample}/{reference}/sequenza/sorted.mpileup.gz"
    params:
        temp="data/work/{sample}/{reference}/sequenza/sorted.mpileup"
    run:
        K={'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9,'10':10,'11':11,'12':12,'13':13,'14':14,'15':15,'16':16,'17':17,'18':18,'19':19,'20':20,'21':21,'22':22,'X':23,'Y':24}
        with open(input[0],'r') as ifile, open(params['temp'],'w') as ofile:
            reader=csv.reader(ifile,delimiter='\t')
            writer=csv.writer(ofile,delimiter='\t')
            writer.writerows(sorted(reader,key=lambda row: (K[row[0]],int(row[1]))))
        shell('bgzip {params["temp"]}')

rule target_mpileup:
    input:
        "data/work/{sample}/{reference}/sequenza/sorted.mpileup.gz"
    output:
        "data/work/{sample}/{reference}/sequenza/targets.mpileup.gz"
    params:
        temp="data/work/{sample}/{reference}/sequenza/targets.mpileup",
        bed=config['resources']['library']['targets_bed']
    run:
        shell('tabix -b 2 -e 2 {input[0]}')
        bed=BedTool(params['bed'])
        tb=tabix.open(input[0]+'.tbi')
        with open(params['temp'],'w') as file:
            writer=csv.writer(file,delimiter='\t')
            for row in bed.sort().merge():
                try:
                    writer.writerows(tb.querys('{}:{}-{}'.format(*row[:3])))
                except tabix.TabixError as e:
                    print(str(e).upper(),'for {}:{}-{}'.format(*row[:3]))
        shell("bgzip {params['temp']}")

rule VarScan:#Add no sort option?
    input:
        #I dont recall if limiting to target mpileup worked.
        unpack(paired_pileup),
        CP="data/work/{tumor}/{targets}/sequenza/{tumor}_confints_CP.txt"#want to change tumor to somatic
    output:
        #raw="data/work/{tumor}/{targets}/varscan/varscan.raw.vcf",#rename
        indel="data/work/{tumor}/{targets}/varscan/varscan.indel.vcf",
        snp="data/work/{tumor}/{targets}/varscan/varscan.snp.vcf"#Note the none plural
    params:
        prefix=lambda wildcards: "data/work/{tumor}/{targets}/varscan/varscan".format(tumor=wildcards.tumor,targets=wildcards.targets),
        args='--min-coverage 3 --min-var-freq 0.08 --p-value 0.10 --somatic-p-value 0.05 --strand-filter 0',
        #purity=get_purity,
        memory='16g'
    #shell:
    run:
        with open(input["CP"],'r') as file:
            lines=file.read().splitlines()
            purity=lines[3].split('\t')[0]#3 for max
        shell(f"java -Xmx{params.memory} -jar $HOME/software/VarScan/VarScan.v2.4.3.jar somatic {input.normal} {input.tumor} {params.prefix} --output-vcf 1 --tumor-purity {purity} {params.args}")
        #bcftools concat -a {output.snp} {output.indel} | bcftools sort -O z -o {output.raw} && tabix -p vcf {output.raw}
        #SS=2
rule VarScan_filter:
    input:
        snp="data/work/{tumor}/{targets}/varscan/varscan.snp.vcf",
        indel="data/work/{tumor}/{targets}/varscan/varscan.indel.vcf"
    output:
        "data/work/{tumor}/{targets}/varscan/varscan.snp.Somatic.vcf",
        "data/work/{tumor}/{targets}/varscan/varscan.indel.Somatic.vcf",
        "data/work/{tumor}/{targets}/varscan/varscan.snp.LOH.vcf",
        "data/work/{tumor}/{targets}/varscan/varscan.indel.LOH.vcf",
        "data/work/{tumor}/{targets}/varscan/varscan.snp.Germline.vcf",
        "data/work/{tumor}/{targets}/varscan/varscan.indel.Germline.vcf"
    params:
        #--min-tumor-freq - Minimum variant allele frequency in tumor [0.10]
        #--max-normal-freq - Maximum variant allele frequency in normal [0.05]
        #--p-value - P-value for high-confidence calling [0.07]
    shell:
            """
            java -jar ~/software/VarScan/VarScan.v2.4.3.jar processSomatic {input.snp}
            java -jar ~/software/VarScan/VarScan.v2.4.3.jar processSomatic {input.indel}
            """

rule bam_readcount_regions:
    #variant=snp or indel
    #type=somatic or LOH
    input:
        "data/work/{tumor}/{targets}/varscan/varscan.{mut}.{class}.vcf"
    output:
        "data/work/{tumor}/{targets}/varscan/varscan.{mut}.{class}.regions"
    script:
        "bam-readcount_regions-snakemake.py"

rule bam_readcount:
    input:
        bam=readcount_bam,
        regions="data/work/{tumor}/{targets}/varscan/varscan.{mut}.{class}.regions"
    output:
        "data/work/{tumor}/{targets}/varscan/varscan.{mut}.{class}.readcounts"
    params:
        ref=config['resources']['reference']['fasta']
    run:
        if wildcards.mut=='indel':
            shell("bam-readcount -i -b 15 -q 1 -w 1 -f {params.ref} -l {input.regions} {input.bam} > {output}")
        else:
            shell("bam-readcount -b 15 -q 1 -w 1 -f {params.ref} -l {input.regions} {input.bam} > {output}")

        #the precision of variant and mutation calling by removing artifacts associated with short-read alignment.
        #-For somatic mutations, generate bam-readcounts with the Tumor BAM. For LOH and Germline, generate readcounts with the Normal BAM
        #-For de novo mutations (trio calling), generate readcounts with the child BAM.
        #The filter requires the bam-readcount utility: https://github.com/genome/bam-readcount

rule fpfilter:
    input:
        vcf="data/work/{tumor}/{targets}/varscan/varscan.{mut}.{class}.vcf",
        readcount="data/work/{tumor}/{targets}/varscan/varscan.{mut}.{class}.readcounts"
    output:
        "data/work/{tumor}/{targets}/varscan/varscan.{mut}.{class}.fpfilter.vcf.gz"
    params:
        output="data/work/{tumor}/{targets}/varscan/varscan.{mut}.{class}.fpfilter.vcf"
    shell:
        """
        java -jar ~/software/VarScan/VarScan.v2.4.3.jar fpfilter {input.vcf} {input.readcount} --output-file {params.output}
        bgzip {params.output} && tabix -p vcf {output}
        """

rule merge_varscan_somatic:
    input:
        snp="data/work/{tumor}/{targets}/varscan/varscan.snp.Somatic.fpfilter.vcf.gz",
        indel="data/work/{tumor}/{targets}/varscan/varscan.indel.Somatic.fpfilter.vcf.gz"
    output:
        "data/work/{tumor}/{targets}/varscan/somatic.fpfilter.vcf.gz"#plural again
    shell:
        "bcftools concat -a {input.snp} {input.indel} | bcftools sort -O z -o {output} && tabix -p vcf {output}"

rule merge_varscan_loh:
    input:
        snp="data/work/{tumor}/{targets}/varscan/varscan.snp.LOH.fpfilter.vcf.gz",
        indel="data/work/{tumor}/{targets}/varscan/varscan.indel.LOH.fpfilter.vcf.gz"
    output:
        "data/work/{tumor}/{targets}/varscan/loh.fpfilter.vcf.gz"#plural again
    shell:
        "bcftools concat -a {input.snp} {input.indel} | bcftools sort -O z -o {output} && tabix -p vcf {output}"

rule merge_varscan_germline:
    input:
        snp="data/work/{tumor}/{targets}/varscan/varscan.snp.Germline.fpfilter.vcf.gz",
        indel="data/work/{tumor}/{targets}/varscan/varscan.indel.Germline.fpfilter.vcf.gz"
    output:
        "data/work/{tumor}/{targets}/varscan/germline.fpfilter.vcf.gz"#plural again
    shell:
        "bcftools concat -a {input.snp} {input.indel} | bcftools sort -O z -o {output} && tabix -p vcf {output}"

        #rule Freebayes

#rule pileup2seqz:
#This can be run with multiprocs now
rule bam2seqz:
    input:
        unpack(paired_pileup)
    params:
        gc="$HOME/resources/Genomes/Human/GRCh37/custom-GRCh37.gc50Base.txt.gz"
    output:
        "data/work/{tumor}/{targets}/sequenza/seqz.gz"
    shell:
        #"sequenza-utils.py pileup2seqz -gc {params.gc} -n {input.normal} -t {input.tumor} | gzip > {output}"
        "sequenza-utils bam2seqz --pileup -gc {params.gc} -n {input.normal} -t {input.tumor} | gzip > {output}"

rule seqz_bin:
    input:
        "data/work/{tumor}/{targets}/sequenza/seqz.gz"
    output:
        "data/work/{tumor}/{targets}/sequenza/seqz.small.gz"
    params:
        bin=50
        #50 for exome 200 for genome
    shell:
        #"sequenza-utils.py seqz-binning -w {params.bin} -a {input} | gzip > {output}"
        "sequenza-utils seqz_binning -w {params.bin} -s {input} -o - | gzip > {output}"
        

rule seqz_extract:
    input:
        "data/work/{tumor}/{targets}/sequenza/seqz.small.gz"
    output:#rename
        "data/work/{tumor}/{targets}/sequenza/{tumor}_confints_CP.txt",
        "data/work/{tumor}/{targets}/sequenza/{tumor}_segments.txt"
    params:
        outdir="data/work/{tumor}/{targets}/sequenza"
    threads:
        4
    script:
        "sequenza-snakemake.R"

rule Manta:
    input:
        unpack(paired_bams)
    output:
        #bam output
        "data/work/{tumor}/{targets}/manta/results/variants/candidateSmallIndels.vcf.gz",
        "data/work/{tumor}/{targets}/manta/results/variants/candidateSV.vcf.gz",
        "data/work/{tumor}/{targets}/manta/results/variants/diploidSV.vcf.gz",
        "data/work/{tumor}/{targets}/manta/results/variants/somaticSV.vcf.gz"
    params:
        workdir="data/work/{tumor}/{targets}/manta",
        reference=config['resources']['reference']['fasta'],
        bedgz=config['resources']['library']['targets_bedgz']
    threads:
        4
    shell:
        """
        $HOME/software/manta/bin/configManta.py --normalBam {input.normal} --tumorBam {input.tumor} --referenceFasta {params.reference} --callRegions {params.bedgz} --exome --runDir {params.workdir}
        {params.workdir}/runWorkflow.py -m local -j {threads}
        """

rule Strelka2:#You sholuld put all concats in a differnt rule. Strelka wont work if the runWorkflow.py script already exists.
    input:
        unpack(paired_bams),
        indels="data/work/{tumor}/{targets}/manta/results/variants/candidateSmallIndels.vcf.gz"
    output:
        #bam output
        snvs="data/work/{tumor}/{targets}/strelka/results/variants/somatic.snvs.vcf.gz",#not snps
        indels="data/work/{tumor}/{targets}/strelka/results/variants/somatic.indels.vcf.gz",
        raw="data/work/{tumor}/{targets}/strelka/somatic.raw.vcf.gz"
    params:
        workdir="data/work/{tumor}/{targets}/strelka",
        reference=config['resources']['reference']['fasta'],
        bedgz=config['resources']['library']['targets_bedgz']
    threads:
        4
    shell:
        """
        $HOME/software/strelka/bin/configureStrelkaSomaticWorkflow.py --normalBam {input.normal} --tumorBam {input.tumor} --indelCandidates {input.indels} --referenceFasta {params.reference} --callRegions {params.bedgz} --exome --runDir {params.workdir}
        {params.workdir}/runWorkflow.py -m local -j {threads}
        bcftools concat -a --threads {threads} {output.snvs} {output.indels} | bcftools sort -O z -o {output.raw}
        tabix -p vcf {output.raw}
        """
        #can add -m, --max-mem <float>[kMG]    maximum memory to use [768M] for sort

rule somatic_bcftools_isec:
    input:
        mutect="data/work/{tumor}/{targets}/mutect/somatic.twice_filtered.vcf.gz",
        strelka="data/work/{tumor}/{targets}/strelka/somatic.raw.vcf.gz",
        vardict="data/work/{tumor}/{targets}/vardict/somatic.twice_filtered.vcf.gz",
        varscan="data/work/{tumor}/{targets}/varscan/somatic.fpfilter.vcf.gz"
    output:
        "data/work/{tumor}/{targets}/concordant/somatic_sites.txt"
    shell:
        "bcftools isec -n +2 -f PASS {input.mutect} {input.strelka} {input.vardict} {input.varscan} > {output}"

###
rule germline_bcftools_isec:
    input:
        vardict="data/work/{tumor}/{targets}/vardict/germline.twice_filtered.vcf.gz",
        varscan="data/work/{tumor}/{targets}/varscan/germline.fpfilter.vcf.gz"
    output:
        "data/work/{tumor}/{targets}/concordant/germline_sites.txt"
    shell:
        "bcftools isec -n +2 -f PASS {input.vardict} {input.varscan} > {output}"

rule loh_bcftools_isec:
    input:
        vardict="data/work/{tumor}/{targets}/vardict/loh.twice_filtered.vcf.gz",
        varscan="data/work/{tumor}/{targets}/varscan/loh.fpfilter.vcf.gz"
    output:
        "data/work/{tumor}/{targets}/concordant/loh_sites.txt"
    shell:
        "bcftools isec -n +2 -f PASS {input.vardict} {input.varscan} > {output}"

rule table_annovar:
    input:
        'hello'
    output:
        'world'
    params:
        humandb="$HOME/resources/annnovar/humandb",
        outfile="path lib stuff?"
    shell:
        "table_annovar.pl {input} {params.humandb} --buildver hg19 --vcfinput --outfile {params.outfile} --protocol refGene,cytoband,gwasCatalog,genomicSuperDups,dbscsnv11,dbnsfp33a,popfreq_max_20150413,exac03,exac03nontcga,gnomad_exome,avsnp150,snp138NonFlagged,icgc21,cosmic84_coding,cosmic84_noncoding,clinvar_20170905 --operation g,r,r,r,f,f,f,f,f,f,f,f,f,f,f,f -remove"

rule HaplotypeCaller_byChr:
    input:
        "bam_input/final/{sample}/GRCh37/{sample}.ready.bam"
    output:
        "data/work/{sample}/gatk/chr{chr}.g.vcf.gz"
    params:
        ref=config['resources']['reference']['fasta'],
        chr=lambda wildcards: wildcards.chr
    shell:
        "gatk --java-options '-Xmx15g' HaplotypeCaller -R {params.ref} -I {intput} -L {params.chr} --emit-ref-confidence GVCF -O {output}"

def sample_gvcf_input(wildcards):
    return expand("-V data/work/{sample}/gatk/chr{chr}.g.vcf.gz",sample=SAMPLES,chr=wildcards.chr)

rule CombineGVCF_byChr:
    input:
        expand("data/work/{sample}/gatk-haplotype.g.vcf.gz",sample=SAMPLES)
    output:
        "data/work/{project}/gatk/chr{chr}.g.vcf.gz"
    params:
        ref=config['resources']['reference']['fasta']
    shell:
        "gatk --java-options '-Xmx30g' CombineGVCFs -R {params.ref} -I {input} -O {gvcf}"

#I can use the other combine method if Im doing it by Chr
#


rule GenomicsDBImport_byChr:
    input:
        sample_gvcf_input
    output:
        "data/work/{project}/gatk/chr{chr}.db"
    params:
        #variants=gvcf_input,
        chr=lambda wildcards: wildcards.chr,
        ref=config['resources']['reference']['fasta'],
        memory='30g'
    shell:
        "gatk --java-options '-Xmx{params.memory}' GenomicsDBImport {input} -R {params.ref} --genomicsDBWorkspace {output} --intervals {params.chr}"

rule SelectIntervals_byChr:
    input:
        "data/work/{project}/gatk/chr{chr}.g.vcf.gz"
    output:
        "data/work/{project}/gatk/chr{chr}.{targets}.g.vcf.gz"
    params:
        reference=config['resources']['reference']['fasta'],
        intervals=config['resources']['library']['targets_intervals'],
        memory='30g'
    shell:
        "gatk --java-options '-Xmx{params.memory}' SelectVariants -I {input} -O {output} -R {params.reference} -L {params.intervals}"

rule GenotypeGVCFs_byChr:
    input:
        "data/work/{project}/gatk/chr{chr}.{targets}.g.vcf.gz"
        #"data/work/{project}/gatk/chr{chr}.db"
    output:
        "data/work/{project}/gatk/chr{chr}.{targets}.raw.vcf.gz"
    params:
        ref=config['resources']['reference']['fasta'],
        chr=lambda wildcards: wildcards.chr
        #intervals=(does this work if I dont subset the intervals?)
    shell:
        "gatk --java-options '-Xmx30g' GenotypeGVCFs -R {params.ref} -I {input} -O {output}"
        #"gatk --java-options '-Xmx30g' GenotypeGVCFs -R {params.ref} -V gendb://{input} -O {output} -L {params.intervals}"

def vcf_chr(wildcards):
    expand("data/work/{project}/gatk/chr{chr}.{targets}.vcf.gz",project=wildcards.project,chr=+['X'],targets=wildcards.targets)

#rule concat_byChr:
#    input:
#    output:
#        raw="",
#        snps
#    params:
#        ref=""
#    shell:
#        "bcftools concat {input} | bcftools sort"

#I need to test this out.
#Probably dont need to sort but maybe its better to, in which case I want the fastest smallest stream
#Concat already into sorted order.
#Or do I try the --naive thing? I dont understand what it means tbh.


rule CODEX2_CoverageQC:
    input:
        #all_bams
        #BAMS
    output:
        Y_qc="data/work/{project}/codex2/coverageQC.csv",
        gc_qc="data/work/{project}/codex2/gc_qc.csv",
        N="data/work/{project}/codex2/library_size_factor.csv"
    params:
    script:
        "wes.codex2_coverage.snakemake.R"

rule CODEX2_ns:
    input:
        Y_qc="data/work/{project}/codex2/coverageQC.csv",
        gc_qc="data/work/{project}/codex2/gc_qc.csv",
        N="data/work/{project}/codex2/library_size_factor.csv"
    output:
        "data/work/{project}/codex2/{chr}.codex2.filtered_segments.txt"
    params:
        chr=lambda wildcards: wildcards.chr,
        normals="normals.list"
    script:
        "wes.codex2_ns.snakemake.R"

#'bcftools norm -m-both "$1" | bcftools norm -f "$HOME"/resources/Genomes/Human/GRCh37/human_g1k_v37.fasta -O z -o "$out".norm.vcf.gz'